{
	"metadata": {
		"kernelspec": {
			"name": "glue_pyspark",
			"display_name": "Glue PySpark",
			"language": "python"
		},
		"language_info": {
			"name": "Python_Glue_Session",
			"mimetype": "text/x-python",
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"pygments_lexer": "python3",
			"file_extension": ".py"
		}
	},
	"nbformat_minor": 4,
	"nbformat": 4,
	"cells": [
		{
			"cell_type": "markdown",
			"source": "# AWS Glue Studio Notebook\n##### You are now running a AWS Glue Studio notebook; To start using your notebook you need to start an AWS Glue Interactive Session.\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "markdown",
			"source": "#### Optional: Run this cell to see available notebook commands (\"magics\").\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "%help",
			"metadata": {
				"editable": true,
				"trusted": true
			},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "markdown",
			"source": "####  Run this cell to set up and start your interactive session.\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "%idle_timeout 2880\n%glue_version 3.0\n%worker_type G.1X\n%number_of_workers 5\n\nimport sys\nfrom awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext\nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job\n  \nsc = SparkContext.getOrCreate()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)",
			"metadata": {
				"editable": true,
				"trusted": true
			},
			"execution_count": 17,
			"outputs": [
				{
					"name": "stderr",
					"text": "You are already connected to a glueetl session 2a587f2d-6a92-4d36-81bc-0e79c3e968e7.\n\nNo change will be made to the current session that is set as glueetl. The session configuration change will apply to newly created sessions.\n",
					"output_type": "stream"
				},
				{
					"name": "stdout",
					"text": "Current idle_timeout is 2880 minutes.\nidle_timeout has been set to 2880 minutes.\n",
					"output_type": "stream"
				},
				{
					"name": "stderr",
					"text": "You are already connected to a glueetl session 2a587f2d-6a92-4d36-81bc-0e79c3e968e7.\n\nNo change will be made to the current session that is set as glueetl. The session configuration change will apply to newly created sessions.\n",
					"output_type": "stream"
				},
				{
					"name": "stdout",
					"text": "Setting Glue version to: 3.0\n",
					"output_type": "stream"
				},
				{
					"name": "stderr",
					"text": "You are already connected to a glueetl session 2a587f2d-6a92-4d36-81bc-0e79c3e968e7.\n\nNo change will be made to the current session that is set as glueetl. The session configuration change will apply to newly created sessions.\n",
					"output_type": "stream"
				},
				{
					"name": "stdout",
					"text": "Previous worker type: G.1X\nSetting new worker type to: G.1X\n",
					"output_type": "stream"
				},
				{
					"name": "stderr",
					"text": "You are already connected to a glueetl session 2a587f2d-6a92-4d36-81bc-0e79c3e968e7.\n\nNo change will be made to the current session that is set as glueetl. The session configuration change will apply to newly created sessions.\n",
					"output_type": "stream"
				},
				{
					"name": "stdout",
					"text": "Previous number of workers: 5\nSetting new number of workers to: 5\n\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "## Read",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "motion_static = glueContext.create_dynamic_frame.from_options(\n    connection_type=\"s3\",\n    connection_options={\n        \"paths\": [\"s3://refit-iot/data/motionsense/static/\"],\n        \"recurse\": True,\n        \"header\": \"true\"\n    },\n    format=\"csv\"\n)\n\n# Read in trips static as dynamic frame\nmotion_streamed = glueContext.create_dynamic_frame.from_options(\n    connection_type=\"s3\",\n    connection_options={\n        \"paths\": [\"s3://refit-iot/data/motionsense/streamed/\"],\n        \"recurse\": True,\n        \"header\": \"true\"\n    },\n    format=\"csv\"\n)\n# Convert to spark df\nmotion_df_static = motion_static.toDF()\nmotion_df_streamed = motion_streamed.toDF()",
			"metadata": {
				"trusted": true
			},
			"execution_count": 18,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "## Fix header",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "# Static\nheader = motion_df_static.rdd.first()\nmotion_final_static = spark.createDataFrame(motion_df_static.rdd.filter(lambda x: x != header), header)\nmotion_final_static = motion_final_static.drop(\"Unnamed: 0\", \"\")\n\n#Streamed\nheader = motion_df_streamed.rdd.first()\nmotion_final_streamed = spark.createDataFrame(motion_df_streamed.rdd.filter(lambda x: x != header), header)\nmotion_final_streamed = motion_final_streamed.drop(\"Unnamed: 0\", \"\")",
			"metadata": {
				"trusted": true
			},
			"execution_count": 51,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "from pyspark.sql.functions import col, to_date, to_timestamp\n\n# Time: str to timestamp\nmotion_final_streamed = motion_final_streamed.withColumn(\"time_series_data\", to_timestamp(col(\"time_series_data\"), \"yyyy-MM-dd HH:mm:ss.SSS\"))\nmotion_final_static = motion_final_static.withColumn(\"time_series_data\", to_timestamp(col(\"time_series_data\"), \"yyyy-MM-dd HH:mm:ss.SSS\"))\n\ncols_to_cast = [val for val in motion_final_streamed.columns if (val != 'test_type' and val != 'time_series_data')]\nfor col_name in cols_to_cast:\n    motion_final_streamed = motion_final_streamed.withColumn(col_name, col(col_name).cast(\"double\"))\n    motion_final_static = motion_final_static.withColumn(col_name, col(col_name).cast(\"double\"))",
			"metadata": {
				"trusted": true
			},
			"execution_count": 52,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "## Write",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "from awsglue.dynamicframe import DynamicFrame\n\n#Convert from spark df to dynamic frame\nmotion_static_dyf = DynamicFrame.fromDF(motion_final_static, glueContext, 'convert')\nmotion_streamed_dyf = DynamicFrame.fromDF(motion_final_streamed, glueContext, 'convert')",
			"metadata": {
				"trusted": true
			},
			"execution_count": 55,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "import boto3\n\n# Streamed\n\n# Housekeeping\ndatabase_name = \"motionsense\"\ntable_name = \"streamed\"\nglue_client = boto3.client('glue')\n\n# Define schema\nschema = motion_streamed_dyf.schema()\ncolumns = [\n    {\n        \"Name\": field.name,\n        \"Type\": field.dataType.typeName()\n    }\n    for field in schema.fields\n]\n\n# Create table configurations\ncreate_table_options_streamed = {\n    \"DatabaseName\": database_name,\n    \"TableInput\": {\n        \"Name\": table_name,\n        \"Description\": \"Streamed data for motion sense\",\n        \n        \"StorageDescriptor\": {\n            \"Columns\": columns,\n            \"Location\": \"s3://refit-iot/final_data_landing/motionsense/streamed/\",\n            \"InputFormat\": \"org.apache.hadoop.mapred.TextInputFormat\",\n            \"OutputFormat\": \"org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat\",\n            \"Compressed\": False,\n            \"SerdeInfo\": {\n                \"SerializationLibrary\": \"org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\",\n                \"Parameters\": {\n                    \"field.delim\": \",\",\n                    \"skip.header.line.count\" : \"1\"\n                }\n            }\n        },\n        \"PartitionKeys\": []\n    }\n}\n\n# Check if streamed table exists\n# If the streamed table does not exist, create\n\ntry: \n    response = glue_client.get_table(\n    DatabaseName=database_name,\n    Name=table_name\n)\n    print(f\"{table_name} already exists. Directly writing...\")\nexcept:\n    glue_client = boto3.client('glue')\n    response_streamed = glue_client.create_table(**create_table_options_streamed)\n    print(f\"{table_name} does not exist. Creating...\")\n\nglueContext.write_dynamic_frame.from_catalog(\n    frame = motion_streamed_dyf,\n    database = database_name,\n    table_name = table_name\n    \n)\n\nprint(f\"Sucessfully wrote to {table_name}\")",
			"metadata": {
				"trusted": true
			},
			"execution_count": 56,
			"outputs": [
				{
					"name": "stdout",
					"text": "streamed does not exist. Creating...\nSucessfully wrote to streamed\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "# Static\n\n# Housekeeping\ndatabase_name = \"motionsense\"\ntable_name = \"static\"\nglue_client = boto3.client('glue')\n\n# Define schema\nschema = motion_static_dyf.schema()\ncolumns = [\n    {\n        \"Name\": field.name,\n        \"Type\": field.dataType.typeName()\n    }\n    for field in schema.fields\n]\n\n# Create table configurations\ncreate_table_options_streamed = {\n    \"DatabaseName\": database_name,\n    \"TableInput\": {\n        \"Name\": table_name,\n        \"Description\": \"Static data for motion sense\",\n        \n        \"StorageDescriptor\": {\n            \"Columns\": columns,\n            \"Location\": \"s3://refit-iot/final_data_landing/motionsense/static/\",\n            \"InputFormat\": \"org.apache.hadoop.mapred.TextInputFormat\",\n            \"OutputFormat\": \"org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat\",\n            \"Compressed\": False,\n            \"SerdeInfo\": {\n                \"SerializationLibrary\": \"org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\",\n                \"Parameters\": {\n                    \"field.delim\": \",\",\n                    \"skip.header.line.count\" : \"1\"\n                }\n            }\n        },\n        \"PartitionKeys\": []\n    }\n}\n\n# Check if streamed table exists\n# If the streamed table does not exist, create\n\ntry: \n    response = glue_client.get_table(\n    DatabaseName=database_name,\n    Name=table_name\n)\n    print(f\"{table_name} already exists. Directly writing...\")\nexcept:\n    glue_client = boto3.client('glue')\n    response_streamed = glue_client.create_table(**create_table_options_streamed)\n    print(f\"{table_name} does not exist. Creating...\")\n\nglueContext.write_dynamic_frame.from_catalog(\n    frame = motion_static_dyf,\n    database = database_name,\n    table_name = table_name\n    \n)\n\nprint(f\"Sucessfully wrote to {table_name}\")",
			"metadata": {
				"trusted": true
			},
			"execution_count": 57,
			"outputs": [
				{
					"name": "stdout",
					"text": "static does not exist. Creating...\nSucessfully wrote to static\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		}
	]
}