{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9140d863",
   "metadata": {},
   "source": [
    "# Data, Libraries & Settings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6919e056",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67b100a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "# Modeling\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Bidirectional, BatchNormalization, Dropout"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "32c52e94",
   "metadata": {},
   "source": [
    "#### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e1aa89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot settings\n",
    "line_width = 0.75\n",
    "\n",
    "# Print all columns from pandas df\n",
    "# pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Print all columns from pandas df\n",
    "# pd.set_option('display.max_rows', None)\n",
    "\n",
    "# MP inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d59d6055",
   "metadata": {},
   "source": [
    "#### Subject Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dbd45a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>188</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "      <td>180</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>48</td>\n",
       "      <td>161</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   code  weight  height  age  gender\n",
       "0     1     102     188   46       1\n",
       "1     2      72     180   28       1\n",
       "2     3      48     161   28       0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get subjects info\n",
    "# Desktop\n",
    "subjects_information_df = pd.read_csv('C:/Users/nuke2/Desktop/NW Work/Data/CDL Usecases/data_subjects_info.csv')\n",
    "# Laptop\n",
    "# subjects_information_df = pd.read_csv('C:/Users/Sam/Desktop/NW Work/DATA/CDL/data_subjects_info.csv')\n",
    "\n",
    "\n",
    "'''\n",
    "Column  Attribute         [Unit]\n",
    "Code:   subject ID        [1 to 24]\n",
    "Weight: Weight of subject [Kg.]\n",
    "Height: Weight of subject [Cm.]\n",
    "Age:    Age of subject    [Years]\n",
    "Gender: Gender of subject [0: F, 1: M]\n",
    "'''\n",
    "subjects_information_df.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b23d2c93",
   "metadata": {},
   "source": [
    "#### Test Data Description"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "395da59e",
   "metadata": {},
   "source": [
    "The test data was collected during these 6 trials:\n",
    "- Downstairs $\\;$[dws]\n",
    "- Upstairs   $\\;$[ups]\n",
    "- Walking    $\\;$[wlk]\n",
    "- Jogging    $\\;$[jog]\n",
    "- Sitting    $\\;$[sit]\n",
    "- Standing   $\\;$[std]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4482ba0",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6854d435",
   "metadata": {},
   "source": [
    "#### Define parameters for data importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "259bee5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Dictionary to specify file numbers of trials so all data can be loaded\n",
    "'''\n",
    "trial_id_dict = {\n",
    "    'dws': [1, 2, 11],\n",
    "    'ups': [3, 4, 12],\n",
    "    'wlk': [7, 8, 15],\n",
    "    'jog': [9, 16],\n",
    "    'sit': [5, 13],\n",
    "    'std': [6, 14]\n",
    "}\n",
    "\n",
    "'''\n",
    "Get dictionary for all gyroscopic measurements\n",
    "'''\n",
    "measurement_dict = {\n",
    "    'attitude': ['attitude.roll', 'attitude.pitch', 'attitude.yaw'],\n",
    "    'gravity':  ['gravity.x', 'gravity.y', 'gravity.z'],\n",
    "    'rotationRate': ['rotationRate.x', 'rotationRate.y', 'rotationRate.z'],\n",
    "    'userAcceleration': ['userAcceleration.x', 'userAcceleration.y', 'userAcceleration.z']\n",
    "}\n",
    "\n",
    "'''\n",
    "Specify number of subjects and list of subject numbers\n",
    "*Assumes the subject ID's go from 1 to n incremented by 1*\n",
    "'''\n",
    "subject_number = 24\n",
    "subject_id_lst = list(range(1, subject_number+1))\n",
    "\n",
    "'''\n",
    "Get folder location with cleaned test data\n",
    "'''\n",
    "# Desktop\n",
    "test_data = 'C:/Users/nuke2/Desktop/NW Work/Data/CDL Usecases/df_all_data.csv'\n",
    "# Laptop\n",
    "# test_data = 'C:/Users/Sam/Desktop/NW Work/DATA/CDL/df_all_data.csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "088464dd",
   "metadata": {},
   "source": [
    "#### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e511b27e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tick_num</th>\n",
       "      <th>attitude.roll</th>\n",
       "      <th>attitude.pitch</th>\n",
       "      <th>attitude.yaw</th>\n",
       "      <th>gravity.x</th>\n",
       "      <th>gravity.y</th>\n",
       "      <th>gravity.z</th>\n",
       "      <th>rotationRate.x</th>\n",
       "      <th>rotationRate.y</th>\n",
       "      <th>rotationRate.z</th>\n",
       "      <th>...</th>\n",
       "      <th>time_since_start</th>\n",
       "      <th>time_series_data</th>\n",
       "      <th>attitude</th>\n",
       "      <th>gravity</th>\n",
       "      <th>rotationRate</th>\n",
       "      <th>userAcceleration</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.528132</td>\n",
       "      <td>-0.733896</td>\n",
       "      <td>0.696372</td>\n",
       "      <td>0.741895</td>\n",
       "      <td>0.669768</td>\n",
       "      <td>-0.031672</td>\n",
       "      <td>0.316738</td>\n",
       "      <td>0.778180</td>\n",
       "      <td>1.082764</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2022-01-01 00:00:00.000</td>\n",
       "      <td>1.832682</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.370498</td>\n",
       "      <td>0.513360</td>\n",
       "      <td>102</td>\n",
       "      <td>188</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.527992</td>\n",
       "      <td>-0.716987</td>\n",
       "      <td>0.677762</td>\n",
       "      <td>0.753099</td>\n",
       "      <td>0.657116</td>\n",
       "      <td>-0.032255</td>\n",
       "      <td>0.842032</td>\n",
       "      <td>0.424446</td>\n",
       "      <td>0.643574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2022-01-01 00:00:00.020</td>\n",
       "      <td>1.818843</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.141648</td>\n",
       "      <td>0.250235</td>\n",
       "      <td>102</td>\n",
       "      <td>188</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.527765</td>\n",
       "      <td>-0.706999</td>\n",
       "      <td>0.670951</td>\n",
       "      <td>0.759611</td>\n",
       "      <td>0.649555</td>\n",
       "      <td>-0.032707</td>\n",
       "      <td>-0.138143</td>\n",
       "      <td>-0.040741</td>\n",
       "      <td>0.343563</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2022-01-01 00:00:00.040</td>\n",
       "      <td>1.812205</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.372530</td>\n",
       "      <td>0.215450</td>\n",
       "      <td>102</td>\n",
       "      <td>188</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.516768</td>\n",
       "      <td>-0.704678</td>\n",
       "      <td>0.675735</td>\n",
       "      <td>0.760709</td>\n",
       "      <td>0.647788</td>\n",
       "      <td>-0.041140</td>\n",
       "      <td>-0.025005</td>\n",
       "      <td>-1.048717</td>\n",
       "      <td>0.035860</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>2022-01-01 00:00:00.060</td>\n",
       "      <td>1.803822</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.049628</td>\n",
       "      <td>0.166728</td>\n",
       "      <td>102</td>\n",
       "      <td>188</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.493941</td>\n",
       "      <td>-0.703918</td>\n",
       "      <td>0.672994</td>\n",
       "      <td>0.760062</td>\n",
       "      <td>0.647210</td>\n",
       "      <td>-0.058530</td>\n",
       "      <td>0.114253</td>\n",
       "      <td>-0.912890</td>\n",
       "      <td>0.047341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2022-01-01 00:00:00.080</td>\n",
       "      <td>1.783334</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.921229</td>\n",
       "      <td>0.408720</td>\n",
       "      <td>102</td>\n",
       "      <td>188</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tick_num  attitude.roll  attitude.pitch  attitude.yaw  gravity.x   \n",
       "0         0       1.528132       -0.733896      0.696372   0.741895  \\\n",
       "1         1       1.527992       -0.716987      0.677762   0.753099   \n",
       "2         2       1.527765       -0.706999      0.670951   0.759611   \n",
       "3         3       1.516768       -0.704678      0.675735   0.760709   \n",
       "4         4       1.493941       -0.703918      0.672994   0.760062   \n",
       "\n",
       "   gravity.y  gravity.z  rotationRate.x  rotationRate.y  rotationRate.z  ...   \n",
       "0   0.669768  -0.031672        0.316738        0.778180        1.082764  ...  \\\n",
       "1   0.657116  -0.032255        0.842032        0.424446        0.643574  ...   \n",
       "2   0.649555  -0.032707       -0.138143       -0.040741        0.343563  ...   \n",
       "3   0.647788  -0.041140       -0.025005       -1.048717        0.035860  ...   \n",
       "4   0.647210  -0.058530        0.114253       -0.912890        0.047341  ...   \n",
       "\n",
       "   time_since_start         time_series_data  attitude gravity  rotationRate   \n",
       "0              0.00  2022-01-01 00:00:00.000  1.832682     1.0      1.370498  \\\n",
       "1              0.02  2022-01-01 00:00:00.020  1.818843     1.0      1.141648   \n",
       "2              0.04  2022-01-01 00:00:00.040  1.812205     1.0      0.372530   \n",
       "3              0.06  2022-01-01 00:00:00.060  1.803822     1.0      1.049628   \n",
       "4              0.08  2022-01-01 00:00:00.080  1.783334     1.0      0.921229   \n",
       "\n",
       "   userAcceleration  weight height  age  gender  \n",
       "0          0.513360     102    188   46       1  \n",
       "1          0.250235     102    188   46       1  \n",
       "2          0.215450     102    188   46       1  \n",
       "3          0.166728     102    188   46       1  \n",
       "4          0.408720     102    188   46       1  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load cleaning data\n",
    "df_all_data = pd.read_csv(test_data)\n",
    "df_all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ea4d9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_data[\"test_type\"].iloc[0:100].to_csv(\"../local_analysis/y_retrain_data_motionsense.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2618411",
   "metadata": {},
   "source": [
    "# Modeling data prep"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10e8569a",
   "metadata": {},
   "source": [
    "#### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdf01e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uhh"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e21e294a",
   "metadata": {},
   "source": [
    "#### Test train validate split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "384b8d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify number of tests\n",
    "num_tests = 16\n",
    "\n",
    "# Specify train numbers\n",
    "train_trial_numbers = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "# Specify test/validation numbers\n",
    "test_and_validation_numbers = [11, 12, 13, 14, 15, 16]\n",
    "\n",
    "# Define dataframes for test train validation sets\n",
    "df_train = pd.DataFrame()\n",
    "df_test = pd.DataFrame()\n",
    "df_validation = pd.DataFrame()\n",
    "\n",
    "# Specify test and validation subjects\n",
    "test_subset = random.sample(subject_id_lst, subject_number//2)\n",
    "val_subset = [n for n in subject_id_lst if n not in test_subset]\n",
    "\n",
    "# Create test train validation dataframes\n",
    "for trial_number in range(1, num_tests + 1):\n",
    "    # Fill in df_train if trial_number in train_trial_numbers\n",
    "    if trial_number in train_trial_numbers:\n",
    "        data_temp = df_all_data[df_all_data.test_trial_number == trial_number]\n",
    "        df_train = pd.concat([df_train, data_temp])\n",
    "    # Fill in df_test / df_validation if trial_number in test_and_validation_numbers\n",
    "    elif trial_number in test_and_validation_numbers:\n",
    "        data_temp = df_all_data[df_all_data.test_trial_number == trial_number]\n",
    "        df_test = pd.concat([df_test, data_temp[data_temp.subject_id.isin(test_subset)]])\n",
    "        df_validation = pd.concat([df_validation, data_temp[data_temp.subject_id.isin(val_subset)]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34ae6543",
   "metadata": {},
   "source": [
    "#### Save data for EC2 instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b58c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_columns = [\n",
    "    'attitude.roll', 'attitude.pitch', 'attitude.yaw',\n",
    "    'gravity.x', 'gravity.y', 'gravity.z',\n",
    "    'rotationRate.x', 'rotationRate.y', 'rotationRate.z',\n",
    "    'userAcceleration.x', 'userAcceleration.y', 'userAcceleration.z',\n",
    "    # 'attitude', 'gravity', 'rotationRate', 'userAcceleration',\n",
    "    # 'weight', 'height', 'age'\n",
    "]\n",
    "\n",
    "df_validation[training_columns].to_csv('X_val_motionsense_lstm.csv', index=False)    \n",
    "\n",
    "df_validation['test_type'].to_csv('y_val_motionsense_lstm.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0516ff88",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_columns = [\n",
    "    'attitude.roll', 'attitude.pitch', 'attitude.yaw',\n",
    "    'gravity.x', 'gravity.y', 'gravity.z',\n",
    "    'rotationRate.x', 'rotationRate.y', 'rotationRate.z',\n",
    "    'userAcceleration.x', 'userAcceleration.y', 'userAcceleration.z',\n",
    "    # 'attitude', 'gravity', 'rotationRate', 'userAcceleration',\n",
    "    # 'weight', 'height', 'age'\n",
    "    \n",
    "    'test_type' # Label\n",
    "]\n",
    "\n",
    "df_train[training_columns].to_csv('train_motionsense_lstm.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "acf42222",
   "metadata": {},
   "source": [
    "#### Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ad75f7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns to be normalized\n",
    "normalize_columns = [\n",
    "    'attitude.roll', 'attitude.pitch', 'attitude.yaw',\n",
    "    'gravity.x', 'gravity.y', 'gravity.z',\n",
    "    'rotationRate.x', 'rotationRate.y', 'rotationRate.z',\n",
    "    'userAcceleration.x', 'userAcceleration.y', 'userAcceleration.z',\n",
    "    # 'attitude', 'gravity', 'rotationRate', 'userAcceleration',\n",
    "    # 'weight', 'height', 'age'\n",
    "]\n",
    "\n",
    "# Initialize a scaler with range (-1, 1)\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "# Fit the scaler to the training data\n",
    "scaler.fit(df_train[normalize_columns])\n",
    "\n",
    "# Transform the training, testing and validation data\n",
    "df_train[normalize_columns] = scaler.transform(df_train[normalize_columns])\n",
    "df_test[normalize_columns] = scaler.transform(df_test[normalize_columns])\n",
    "df_validation[normalize_columns] = scaler.transform(df_validation[normalize_columns])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d6d41a1",
   "metadata": {},
   "source": [
    "#### Save scalar function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "67dcdc70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['motionsense_lstm_scalar.save']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "scaler_filename = \"motionsense_lstm_scalar.save\"\n",
    "joblib.dump(scaler, scaler_filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04fd6d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loading scalar\n",
    "scaler = joblib.load(scaler_filename) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b80a020c",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92d9aac6",
   "metadata": {},
   "source": [
    "#### LSTM settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8021be8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set length of memory (# of observation model looks back)\n",
    "n_timesteps = 50\n",
    "\n",
    "# Set number of categories model is predicting\n",
    "n_categories = 6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "286e8d31",
   "metadata": {},
   "source": [
    "#### Select LSTM columns / data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2bc99621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column Selection for LSTM input\n",
    "lstm_columns = [    \n",
    "    'attitude.roll', # Roll attitude of device    \n",
    "    'attitude.pitch', # Pitch attitude of device    \n",
    "    'attitude.yaw', # Yaw attitude of device    \n",
    "    'gravity.x', # x-axis measurement of gravity    \n",
    "    'gravity.y', # y-axis measurement of gravity    \n",
    "    'gravity.z', # z-axis measurement of gravity    \n",
    "    'rotationRate.x', # x-axis measurement of rotation rate    \n",
    "    'rotationRate.y', # y-axis measurement of rotation rate    \n",
    "    'rotationRate.z', # z-axis measurement of rotation rate    \n",
    "    'userAcceleration.x', # x-axis measurement of user acceleration    \n",
    "    'userAcceleration.y', # y-axis measurement of user acceleration    \n",
    "    'userAcceleration.z', # z-axis measurement of user acceleration     \n",
    "    # 'attitude', # Total attitude\n",
    "    # 'gravity', # Total gravity\n",
    "    # 'rotationRate', # Total rotationRate\n",
    "    # 'userAcceleration', # Total userAcceleration   \n",
    "#     'weight', # Weight of subject\n",
    "#     'height', # Height of subject\n",
    "#     'age', # Age of subject\n",
    "#     'gender' # Gender of subject\n",
    "]\n",
    "\n",
    "# Get train test validation split\n",
    "df_train_lstm = df_train[lstm_columns]\n",
    "df_val_lstm = df_validation[lstm_columns]\n",
    "df_test_lstm = df_test[lstm_columns]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad2102ca",
   "metadata": {},
   "source": [
    "#### Wrangle data to be run in LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a3d1c084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrames to arrays\n",
    "array_train_lstm = df_train_lstm.values\n",
    "array_val_lstm = df_val_lstm.values\n",
    "array_test_lstm = df_test_lstm.values\n",
    "\n",
    "# Create arrays to store values for each test and validation trial\n",
    "array_test_lstm_trails = {}\n",
    "X_test_lstm_trials = {}\n",
    "array_val_lstm_trails = {}\n",
    "X_val_lstm_trials = {}\n",
    "\n",
    "for key in trial_id_dict:\n",
    "    # Extract the values for each test trial\n",
    "    array_test_lstm_trails[key] = df_test[df_test.test_type == key][lstm_columns].values\n",
    "    X_test_lstm_trials[key] = array_test_lstm_trails[key]\n",
    "    # Extract the values for each validation trial\n",
    "    array_val_lstm_trails[key] = df_validation[df_validation.test_type == key][lstm_columns].values\n",
    "    X_val_lstm_trials[key] = array_val_lstm_trails[key]    \n",
    "\n",
    "# Store the number of features and the number of time steps\n",
    "n_features = len(lstm_columns)\n",
    "n_timesteps = n_timesteps\n",
    "\n",
    "# Initialize arrays to store the LSTM inputs for train, validation, and test sets\n",
    "X_train_lstm = np.zeros((array_train_lstm.shape[0], n_timesteps, n_features))\n",
    "X_val_lstm = np.zeros((array_val_lstm.shape[0], n_timesteps, n_features))\n",
    "X_test_lstm = np.zeros((array_test_lstm.shape[0], n_timesteps, n_features))\n",
    "for key in trial_id_dict:\n",
    "    X_test_lstm_trials[key] = np.zeros((X_test_lstm_trials[key].shape[0], n_timesteps, n_features))\n",
    "    X_val_lstm_trials[key] = np.zeros((X_val_lstm_trials[key].shape[0], n_timesteps, n_features))\n",
    "\n",
    "# Loop through the arrays for each set and create the LSTM input\n",
    "for arr in [X_train_lstm, X_val_lstm, X_test_lstm]:\n",
    "    if np.array_equal(arr, X_train_lstm):\n",
    "        for i in range(n_timesteps, array_train_lstm.shape[0]):\n",
    "            X_train_lstm[i-n_timesteps] = array_train_lstm[i-n_timesteps:i]\n",
    "    elif np.array_equal(arr, X_val_lstm):\n",
    "        for i in range(n_timesteps, array_val_lstm.shape[0]):\n",
    "            X_val_lstm[i-n_timesteps] = array_val_lstm[i-n_timesteps:i]\n",
    "    elif np.array_equal(arr, X_test_lstm):\n",
    "        for i in range(n_timesteps, array_test_lstm.shape[0]):\n",
    "            X_test_lstm[i-n_timesteps] = array_test_lstm[i-n_timesteps:i]\n",
    "\n",
    "# Loop through the arrays for each test trial and create the LSTM input\n",
    "for key in trial_id_dict:\n",
    "    for i in range(n_timesteps, X_test_lstm_trials[key].shape[0]):\n",
    "            X_test_lstm_trials[key][i-n_timesteps] = array_test_lstm_trails[key][i-n_timesteps:i]\n",
    "    for i in range(n_timesteps, X_val_lstm_trials[key].shape[0]):\n",
    "            X_val_lstm_trials[key][i-n_timesteps] = array_val_lstm_trails[key][i-n_timesteps:i]\n",
    "\n",
    "# Initilize encoder and set categories\n",
    "encoder = LabelEncoder()\n",
    "n_categories = n_categories\n",
    "\n",
    "# Encode the training y data and convert to categorical using one-hot encoding\n",
    "encoder.fit(df_train['test_type'])\n",
    "y_train_lstm = encoder.transform(df_train['test_type'])\n",
    "y_train_lstm = to_categorical(y_train_lstm, num_classes = n_categories)\n",
    "\n",
    "# Encode the validation y data and convert to categorical using one-hot encoding\n",
    "y_val_lstm = encoder.transform(df_validation['test_type'])\n",
    "y_val_lstm = to_categorical(y_val_lstm, num_classes = n_categories)\n",
    "\n",
    "# Encode the test y data and convert to categorical using one-hot encoding\n",
    "y_test_lstm = encoder.transform(df_test['test_type'])\n",
    "y_test_lstm = to_categorical(y_test_lstm, num_classes = n_categories)\n",
    "\n",
    "# Encode the test y data for each trial and convert to categorical using one-hot encoding\n",
    "y_test_lstm_trials = {}\n",
    "for key in trial_id_dict:\n",
    "    y_test_lstm_trials[key] = encoder.transform(df_test[df_test.test_type == key]['test_type'])\n",
    "    y_test_lstm_trials[key] = to_categorical(y_test_lstm_trials[key], num_classes = n_categories)\n",
    "    \n",
    "# Encode the validation y data for each trial and convert to categorical using one-hot encoding\n",
    "y_val_lstm_trials = {}\n",
    "for key in trial_id_dict:\n",
    "    y_val_lstm_trials[key] = encoder.transform(df_validation[df_validation.test_type == key]['test_type'])\n",
    "    y_val_lstm_trials[key] = to_categorical(y_val_lstm_trials[key], num_classes = n_categories)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb6f8e28",
   "metadata": {},
   "source": [
    "#### Save label encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "355536b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('motionsense_lstm_label_encoder.npy', encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "780b8b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loading encoder\n",
    "encoder.classes_ = np.load('motionsense_lstm_label_encoder.npy', allow_pickle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb6f400b",
   "metadata": {},
   "source": [
    "#### Create LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "632ef889",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "\n",
    "    # Initialize a sequential model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add a bidirectional LSTM layer to the model\n",
    "    model.add(Bidirectional(LSTM(units=16, input_shape=(n_timesteps, n_features))))\n",
    "\n",
    "    # Add a dense output layer with 6 units and a softmax activation function\n",
    "    model.add(Dense(n_categories, activation='softmax'))\n",
    "\n",
    "    # Compile the model using the Adam optimizer, categorical crossentropy loss, and accuracy metrics\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = create_model()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cef105f1",
   "metadata": {},
   "source": [
    "#### Check if GPU available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5847dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "# Enable GPU if available\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    print(\"No GPU found\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1091c21d",
   "metadata": {},
   "source": [
    "#### Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f026c615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 4586/16898 [=======>......................] - ETA: 1:35 - loss: 0.6579 - accuracy: 0.7195"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\nuke2\\Desktop\\NW Work\\CDL usecases\\MotionSense\\Motionsense - Modeling.ipynb Cell 34\u001b[0m in \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nuke2/Desktop/NW%20Work/CDL%20usecases/MotionSense/Motionsense%20-%20Modeling.ipynb#X45sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Train the model for 5 epochs using mini-batches of size 64\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/nuke2/Desktop/NW%20Work/CDL%20usecases/MotionSense/Motionsense%20-%20Modeling.ipynb#X45sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train_lstm, y_train_lstm, epochs\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nuke2/Desktop/NW%20Work/CDL%20usecases/MotionSense/Motionsense%20-%20Modeling.ipynb#X45sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m model\u001b[39m.\u001b[39msummary()\n",
      "File \u001b[1;32mc:\\Users\\nuke2\\miniconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\nuke2\\miniconda3\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model for 5 epochs using mini-batches of size 64\n",
    "model.fit(X_train_lstm, y_train_lstm, epochs=5, batch_size=64)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8fdeecdb",
   "metadata": {},
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec3c839f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path to save model\n",
    "model_path = \"../MotionSense/\"\n",
    "model.save(model_path + \"MotionSense_LSTM.h5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d749a517",
   "metadata": {},
   "source": [
    "#### Load model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48cb4202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 64)               11520     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,910\n",
      "Trainable params: 11,910\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load model and check it's architecture\n",
    "loaded_model = tf.keras.models.load_model(model_path + \"MotionSense_LSTM.h5\")\n",
    "loaded_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "22a72cc5",
   "metadata": {},
   "source": [
    "#### Get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db00c16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5193/5193 [==============================] - 19s 4ms/step\n",
      "358/358 [==============================] - 1s 4ms/step\n",
      "439/439 [==============================] - 2s 4ms/step\n",
      "903/903 [==============================] - 3s 3ms/step\n",
      "490/490 [==============================] - 2s 4ms/step\n",
      "1773/1773 [==============================] - 6s 3ms/step\n",
      "1233/1233 [==============================] - 4s 3ms/step\n",
      "5165/5165 [==============================] - 20s 4ms/step\n",
      "346/346 [==============================] - 1s 4ms/step\n",
      "437/437 [==============================] - 2s 4ms/step\n",
      "1138/1138 [==============================] - 4s 4ms/step\n",
      "446/446 [==============================] - 2s 4ms/step\n",
      "1482/1482 [==============================] - 6s 4ms/step\n",
      "1318/1318 [==============================] - 5s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict on test data using the trained model\n",
    "y_pred_test = model.predict(X_test_lstm)\n",
    "\n",
    "# Test trial accuracy\n",
    "trial_acc_test = {}\n",
    "for key in trial_id_dict:\n",
    "    temp_ground = np.argmax(y_test_lstm_trials[key], axis=1)\n",
    "    temp_predictions = np.argmax(model.predict(X_test_lstm_trials[key]), axis=1)\n",
    "    trial_acc_test[key] = np.mean(temp_ground == temp_predictions)\n",
    "\n",
    "# Predict on validation data using the trained model\n",
    "y_pred_val = model.predict(X_val_lstm)\n",
    "\n",
    "# Validation trial accuracy\n",
    "trial_acc_val = {}\n",
    "for key in trial_id_dict:\n",
    "    temp_ground = np.argmax(y_val_lstm_trials[key], axis=1)\n",
    "    temp_predictions = np.argmax(model.predict(X_val_lstm_trials[key]), axis=1)\n",
    "    trial_acc_val[key] = np.mean(temp_ground == temp_predictions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16f97704",
   "metadata": {},
   "source": [
    "#### Print predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "702c5d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] -- Total Accuracy\n",
      "Test: 92.814%\n",
      "Validation (Test #2): 90.061%\n",
      "\n",
      "[INFO] -- Test Trials Accuracy\n",
      "dws: 93.842%\n",
      "ups: 85.873%\n",
      "wlk: 95.729%\n",
      "jog: 88.041%\n",
      "sit: 99.801%\n",
      "std: 84.535%\n",
      "\n",
      "[INFO] -- Validation Trials Accuracy:\n",
      "dws: 95.438%\n",
      "ups: 85.736%\n",
      "wlk: 89.968%\n",
      "jog: 95.74%\n",
      "sit: 80.94%\n",
      "std: 98.392%\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Get total test and validation accuracies\n",
    "Get trial test and validation accuracies\n",
    "'''\n",
    "\n",
    "# Convert one-hot encoded outputs back to class indices\n",
    "y_ground_test = np.argmax(y_test_lstm, axis=1)\n",
    "y_ground_val = np.argmax(y_val_lstm, axis=1)\n",
    "\n",
    "# Obtain class predictions from model output\n",
    "y_pred_test_classes = np.argmax(y_pred_test, axis=1)\n",
    "y_pred_val_classes = np.argmax(y_pred_val, axis=1)\n",
    "\n",
    "# Calculate accuracy by comparing ground truth and predicted classes\n",
    "accuracy_test = np.mean(y_ground_test == y_pred_test_classes)\n",
    "accuracy_val = np.mean(y_ground_val == y_pred_val_classes)\n",
    "\n",
    "# Print LSTM results\n",
    "print(f\"[INFO] -- Total Accuracy\")\n",
    "print(f\"Test: {round(accuracy_test * 100, 3)}%\")\n",
    "print(f\"Validation (Test #2): {round(accuracy_val * 100, 3)}%\")\n",
    "print(f\"\")\n",
    "print(f\"[INFO] -- Test Trials Accuracy\")\n",
    "for key in trial_acc_test:\n",
    "    print(f\"{key}: {round(trial_acc_test[key] * 100, 3)}%\")\n",
    "print(\"\")\n",
    "print(f\"[INFO] -- Validation Trials Accuracy:\")\n",
    "for key in trial_acc_test:\n",
    "    print(f\"{key}: {round(trial_acc_val[key] * 100, 3)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320d93a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ha!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
